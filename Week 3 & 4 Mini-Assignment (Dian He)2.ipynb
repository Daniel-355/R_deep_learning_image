{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 & 4 Mini-Assignment (Dian He)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employing a scalable 3D ResNet architecture learn to predict the subject’s sex (classification) from T1–weighted brain MR images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SimpleITK\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/aa/b74ae9af1750f6825a5846971d4654666b28a482a38bca2faaff5fe5f96e/SimpleITK-2.0.1-cp35-cp35m-manylinux1_x86_64.whl (44.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 44.9MB 31kB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: SimpleITK\n",
      "Successfully installed SimpleITK-2.0.1\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install SimpleITK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Downloading https://files.pythonhosted.org/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl (103kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 7.0MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: xlrd\n",
      "Successfully installed xlrd-1.2.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File mra.tar already exists. Skipping download.\n",
      "File pd.tar already exists. Skipping download.\n",
      "File t2.tar already exists. Skipping download.\n",
      "File t1.tar already exists. Skipping download.\n",
      "File demographic.xls already exists. Skipping download.\n",
      "Extracting IXI HH data from mra.tar.\n",
      "Extracting IXI HH data from pd.tar.\n",
      "Extracting IXI HH data from t2.tar.\n",
      "Extracting IXI HH data from t1.tar.\n",
      "['Table', 'Ethnicity', 'Marital Status', 'Occupation', 'Qualification', 'Study Date']\n",
      "Resampling IXI012\n",
      "T1: (230, 230, 134) (1.0, 1.0, 1.0)\n",
      "T2: (230, 230, 134) (1.0, 1.0, 1.0)\n",
      "PD: (230, 230, 134) (1.0, 1.0, 1.0)\n",
      "MRA: (230, 230, 134) (1.0, 1.0, 1.0)\n",
      "T1: (115, 115, 67) (2.0, 2.0, 2.0)\n",
      "T2: (115, 115, 67) (2.0, 2.0, 2.0)\n",
      "PD: (115, 115, 67) (2.0, 2.0, 2.0)\n",
      "MRA: (115, 115, 67) (2.0, 2.0, 2.0)\n",
      "Resampling IXI013\n",
      "T1: (230, 230, 139) (1.0, 1.0, 1.0)\n",
      "T2: (230, 230, 139) (1.0, 1.0, 1.0)\n",
      "PD: (230, 230, 139) (1.0, 1.0, 1.0)\n",
      "MRA: (230, 230, 139) (1.0, 1.0, 1.0)\n",
      "T1: (115, 115, 70) (2.0, 2.0, 2.0)\n",
      "T2: (115, 115, 70) (2.0, 2.0, 2.0)\n",
      "PD: (115, 115, 70) (2.0, 2.0, 2.0)\n",
      "MRA: (115, 115, 70) (2.0, 2.0, 2.0)\n",
      "Resampling IXI015\n",
      "T1: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "Resampling IXI033\n",
      "T1: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "Resampling IXI034\n",
      "T1: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "Resampling IXI039\n",
      "T1: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 144) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 72) (2.0, 2.0, 2.0)\n",
      "Resampling IXI048\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI049\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI051\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI052\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI056\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI057\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI059\n",
      "T1: (240, 240, 163) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 163) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 163) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 163) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI067\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI072\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI079\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI080\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI083\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI092\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI093\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI094\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI095\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI096\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI097\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI102\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI104\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI105\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI126\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI127\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI128\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI130\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI131\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI132\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI136\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI137\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI146\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI148\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI150\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI159\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI160\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI161\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI162\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI163\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI165\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI167\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI168\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI173\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI174\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI175\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI176\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI180\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI195\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI201\n",
      "T1: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "T2: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "PD: (240, 240, 162) (1.0, 1.0, 1.0)\n",
      "MRA: (240, 240, 162) (1.0, 1.0, 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "T2: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "PD: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "MRA: (120, 120, 81) (2.0, 2.0, 2.0)\n",
      "Resampling IXI202\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Download and extract the IXI Hammersmith Hospital 3T dataset\n",
    "url: http://brain-development.org/ixi-dataset/\n",
    "ref: IXI – Information eXtraction from Images (EPSRC GR/S21533/02)\n",
    "\"\"\"\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from future.standard_library import install_aliases  # py 2/3 compatability\n",
    "install_aliases()\n",
    "\n",
    "from urllib.request import FancyURLopener\n",
    "\n",
    "import os.path\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "DOWNLOAD_IMAGES = True\n",
    "EXTRACT_IMAGES = True\n",
    "PROCESS_OTHER = True\n",
    "RESAMPLE_IMAGES = True\n",
    "CLEAN_UP = True\n",
    "\n",
    "\n",
    "def resample_image(itk_image, out_spacing=(1.0, 1.0, 1.0), is_label=False):\n",
    "    original_spacing = itk_image.GetSpacing()\n",
    "    original_size = itk_image.GetSize()\n",
    "\n",
    "    out_size = [int(np.round(original_size[0] * (original_spacing[0] / out_spacing[0]))),\n",
    "                int(np.round(original_size[1] * (original_spacing[1] / out_spacing[1]))),\n",
    "                int(np.round(original_size[2] * (original_spacing[2] / out_spacing[2])))]\n",
    "\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetOutputSpacing(out_spacing)\n",
    "    resample.SetSize(out_size)\n",
    "    resample.SetOutputDirection(itk_image.GetDirection())\n",
    "    resample.SetOutputOrigin(itk_image.GetOrigin())\n",
    "    resample.SetTransform(sitk.Transform())\n",
    "    resample.SetDefaultPixelValue(itk_image.GetPixelIDValue())\n",
    "\n",
    "    if is_label:\n",
    "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    else:\n",
    "        resample.SetInterpolator(sitk.sitkBSpline)\n",
    "\n",
    "    return resample.Execute(itk_image)\n",
    "\n",
    "\n",
    "def reslice_image(itk_image, itk_ref, is_label=False):\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetReferenceImage(itk_ref)\n",
    "\n",
    "    if is_label:\n",
    "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    else:\n",
    "        resample.SetInterpolator(sitk.sitkBSpline)\n",
    "\n",
    "    return resample.Execute(itk_image)\n",
    "\n",
    "\n",
    "urls = {}\n",
    "urls['t1'] = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T1.tar'\n",
    "urls['t2'] = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T2.tar'\n",
    "urls['pd'] = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-PD.tar'\n",
    "urls['mra'] = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-MRA.tar'\n",
    "urls['demographic'] = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI.xls'\n",
    "\n",
    "fnames = {}\n",
    "fnames['t1'] = 't1.tar'\n",
    "fnames['t2'] = 't2.tar'\n",
    "fnames['pd'] = 'pd.tar'\n",
    "fnames['mra'] = 'mra.tar'\n",
    "fnames['demographic'] = 'demographic.xls'\n",
    "\n",
    "\n",
    "if DOWNLOAD_IMAGES:\n",
    "    # Download all IXI data\n",
    "    for key, url in urls.items():\n",
    "\n",
    "        if not os.path.isfile(fnames[key]):\n",
    "            print('Downloading {} from {}'.format(fnames[key], url))\n",
    "            curr_file = FancyURLopener()\n",
    "            curr_file.retrieve(url, fnames[key])\n",
    "        else:\n",
    "            print('File {} already exists. Skipping download.'.format(\n",
    "                fnames[key]))\n",
    "\n",
    "if EXTRACT_IMAGES:\n",
    "    # Extract the HH subset of IXI\n",
    "    for key, fname in fnames.items():\n",
    "\n",
    "        if (fname.endswith('.tar')):\n",
    "            print('Extracting IXI HH data from {}.'.format(fnames[key]))\n",
    "            output_dir = os.path.join('./orig/', key)\n",
    "\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            t = tarfile.open(fname, 'r')\n",
    "            for member in t.getmembers():\n",
    "                if '-HH-' in member.name:\n",
    "                    t.extract(member, output_dir)\n",
    "\n",
    "\n",
    "if PROCESS_OTHER:\n",
    "    # Process the demographic xls data and save to csv\n",
    "    xls = pd.ExcelFile('demographic.xls')\n",
    "    print(xls.sheet_names)\n",
    "\n",
    "    df = xls.parse('Table')\n",
    "    for index, row in df.iterrows():\n",
    "        IXI_id = 'IXI{:03d}'.format(row['IXI_ID'])\n",
    "        df.loc[index, 'IXI_ID'] = IXI_id\n",
    "\n",
    "        t1_exists = len(glob.glob('./orig/t1/{}*.nii.gz'.format(IXI_id)))\n",
    "        t2_exists = len(glob.glob('./orig/t2/{}*.nii.gz'.format(IXI_id)))\n",
    "        pd_exists = len(glob.glob('./orig/pd/{}*.nii.gz'.format(IXI_id)))\n",
    "        mra_exists = len(glob.glob('./orig/mra/{}*.nii.gz'.format(IXI_id)))\n",
    "\n",
    "        # Check if each entry is complete and drop if not\n",
    "        # if not t1_exists and not t2_exists and not pd_exists and not mra\n",
    "        # exists:\n",
    "        if not (t1_exists and t2_exists and pd_exists and mra_exists):\n",
    "            df.drop(index, inplace=True)\n",
    "\n",
    "    # Write to csv file\n",
    "    df.to_csv('demographic_HH.csv', index=False)\n",
    "\n",
    "if RESAMPLE_IMAGES:\n",
    "    # Resample the IXI HH T2 images to 1mm isotropic and reslice all\n",
    "    # others to it\n",
    "    df = pd.read_csv('demographic_HH.csv', dtype=object, keep_default_na=False,\n",
    "                     na_values=[]).as_matrix()\n",
    "\n",
    "    for i in df:\n",
    "        IXI_id = i[0]\n",
    "        print('Resampling {}'.format(IXI_id))\n",
    "\n",
    "        t1_fn = glob.glob('./orig/t1/{}*.nii.gz'.format(IXI_id))[0]\n",
    "        t2_fn = glob.glob('./orig/t2/{}*.nii.gz'.format(IXI_id))[0]\n",
    "        pd_fn = glob.glob('./orig/pd/{}*.nii.gz'.format(IXI_id))[0]\n",
    "        mra_fn = glob.glob('./orig/mra/{}*.nii.gz'.format(IXI_id))[0]\n",
    "\n",
    "        t1 = sitk.ReadImage(t1_fn)\n",
    "        t2 = sitk.ReadImage(t2_fn)\n",
    "        pd = sitk.ReadImage(pd_fn)\n",
    "        mra = sitk.ReadImage(mra_fn)\n",
    "\n",
    "        # Resample to 1mm isotropic resolution\n",
    "        t2_1mm = resample_image(t2)\n",
    "        t1_1mm = reslice_image(t1, t2_1mm)\n",
    "        pd_1mm = reslice_image(pd, t2_1mm)\n",
    "        mra_1mm = reslice_image(mra, t2_1mm)\n",
    "\n",
    "        output_dir = os.path.join('./1mm/', IXI_id)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        print('T1: {} {}'.format(t1_1mm.GetSize(), t1_1mm.GetSpacing()))\n",
    "        print('T2: {} {}'.format(t2_1mm.GetSize(), t2_1mm.GetSpacing()))\n",
    "        print('PD: {} {}'.format(pd_1mm.GetSize(), pd_1mm.GetSpacing()))\n",
    "        print('MRA: {} {}'.format(mra_1mm.GetSize(), mra_1mm.GetSpacing()))\n",
    "\n",
    "        sitk.WriteImage(t1_1mm, os.path.join(output_dir, 'T1_1mm.nii.gz'))\n",
    "        sitk.WriteImage(t2_1mm, os.path.join(output_dir, 'T2_1mm.nii.gz'))\n",
    "        sitk.WriteImage(pd_1mm, os.path.join(output_dir, 'PD_1mm.nii.gz'))\n",
    "        sitk.WriteImage(mra_1mm, os.path.join(output_dir, 'MRA_1mm.nii.gz'))\n",
    "\n",
    "        # Resample to 2mm isotropic resolution\n",
    "        t2_2mm = resample_image(t2, out_spacing=[2.0, 2.0, 2.0])\n",
    "        t1_2mm = reslice_image(t1, t2_2mm)\n",
    "        pd_2mm = reslice_image(pd, t2_2mm)\n",
    "        mra_2mm = reslice_image(mra, t2_2mm)\n",
    "\n",
    "        output_dir = os.path.join('./2mm/', IXI_id)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        print('T1: {} {}'.format(t2_2mm.GetSize(), t1_2mm.GetSpacing()))\n",
    "        print('T2: {} {}'.format(t2_2mm.GetSize(), t2_2mm.GetSpacing()))\n",
    "        print('PD: {} {}'.format(pd_2mm.GetSize(), pd_2mm.GetSpacing()))\n",
    "        print('MRA: {} {}'.format(mra_2mm.GetSize(), mra_2mm.GetSpacing()))\n",
    "\n",
    "        sitk.WriteImage(t1_2mm, os.path.join(output_dir, 'T1_2mm.nii.gz'))\n",
    "        sitk.WriteImage(t2_2mm, os.path.join(output_dir, 'T2_2mm.nii.gz'))\n",
    "        sitk.WriteImage(pd_2mm, os.path.join(output_dir, 'PD_2mm.nii.gz'))\n",
    "        sitk.WriteImage(mra_2mm, os.path.join(output_dir, 'MRA_2mm.nii.gz'))\n",
    "\n",
    "\n",
    "if CLEAN_UP:\n",
    "    # Remove the .tar files\n",
    "    for key, fname in fnames.items():\n",
    "        if (fname.endswith('.tar')):\n",
    "            os.remove(fname)\n",
    "\n",
    "    # Remove all data in original resolution\n",
    "    os.system('rm -rf orig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from dltk.io.augmentation import extract_random_example_array, flip\n",
    "from dltk.io.preprocessing import whitening\n",
    "\n",
    "\n",
    "def read_fn(file_references, mode, params=None):\n",
    "    \"\"\"A custom python read function for interfacing with nii image files.\n",
    "    Args:\n",
    "        file_references (list): A list of lists containing file references,\n",
    "            such as [['id_0', 'image_filename_0', target_value_0], ...,\n",
    "            ['id_N', 'image_filename_N', target_value_N]].\n",
    "        mode (str): One of the tf.estimator.ModeKeys strings: TRAIN, EVAL or\n",
    "            PREDICT.\n",
    "        params (dict, optional): A dictionary to parametrise read_fn outputs\n",
    "            (e.g. reader_params = {'n_examples': 10, 'example_size':\n",
    "            [64, 64, 64], 'extract_examples': True}, etc.).\n",
    "    Yields:\n",
    "        dict: A dictionary of reader outputs for dltk.io.abstract_reader.\n",
    "    \"\"\"\n",
    "\n",
    "    def _augment(img):\n",
    "        \"\"\"An image augmentation function\"\"\"\n",
    "        return flip(img, axis=2)\n",
    "\n",
    "    for f in file_references:\n",
    "        subject_id = f[0]\n",
    "\n",
    "        data_path = '../../../data/IXI_HH/2mm'\n",
    "\n",
    "        # Read the image nii with sitk\n",
    "        t1_fn = os.path.join(data_path, '{}/T1_2mm.nii.gz'.format(subject_id))\n",
    "        t1 = sitk.GetArrayFromImage(sitk.ReadImage(str(t1_fn)))\n",
    "\n",
    "        # Normalise volume image\n",
    "        t1 = whitening(t1)\n",
    "\n",
    "        images = np.expand_dims(t1, axis=-1).astype(np.float32)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            yield {'features': {'x': images}, 'img_id': subject_id}\n",
    "\n",
    "        # Parse the sex classes from the file_references [1,2] and shift them\n",
    "        # to [0,1]\n",
    "        sex = np.int(f[1]) - 1\n",
    "        y = np.expand_dims(sex, axis=-1).astype(np.int32)\n",
    "\n",
    "        # Augment if used in training mode\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            images = _augment(images)\n",
    "\n",
    "        # Check if the reader is supposed to return training examples or full\n",
    "        # images\n",
    "        if params['extract_examples']:\n",
    "            images = extract_random_example_array(\n",
    "                image_list=images,\n",
    "                example_size=params['example_size'],\n",
    "                n_examples=params['n_examples'])\n",
    "\n",
    "            for e in range(params['n_examples']):\n",
    "                yield {'features': {'x': images[e].astype(np.float32)},\n",
    "                       'labels': {'y': y.astype(np.float32)},\n",
    "                       'img_id': subject_id}\n",
    "\n",
    "        else:\n",
    "            yield {'features': {'x': images},\n",
    "                   'labels': {'y': y.astype(np.float32)},\n",
    "                   'img_id': subject_id}\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (http.py, line 156)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python3.5/site-packages/feedparser/http.py\"\u001b[0;36m, line \u001b[0;32m156\u001b[0m\n\u001b[0;31m    new_pieces[1] = f'{url_pieces.hostname}:{url_pieces.port}'\u001b[0m\n\u001b[0m                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from dltk.networks.regression_classification.resnet import resnet_3d\n",
    "from dltk.io.abstract_reader import Reader\n",
    "\n",
    "from reader import read_fn\n",
    "\n",
    "\n",
    "EVAL_EVERY_N_STEPS = 100\n",
    "EVAL_STEPS = 5\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "NUM_CHANNELS = 1\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "SHUFFLE_CACHE_SIZE = 32\n",
    "\n",
    "MAX_STEPS = 50000\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    \"\"\"Model function to construct a tf.estimator.EstimatorSpec. It creates a\n",
    "        network given input features (e.g. from a dltk.io.abstract_reader) and\n",
    "        training targets (labels). Further, loss, optimiser, evaluation ops and\n",
    "        custom tensorboard summary ops can be added. For additional information,\n",
    "         please refer to https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#model_fn.\n",
    "    Args:\n",
    "        features (tf.Tensor): Tensor of input features to train from. Required\n",
    "            rank and dimensions are determined by the subsequent ops\n",
    "            (i.e. the network).\n",
    "        labels (tf.Tensor): Tensor of training targets or labels. Required rank\n",
    "            and dimensions are determined by the network output.\n",
    "        mode (str): One of the tf.estimator.ModeKeys: TRAIN, EVAL or PREDICT\n",
    "        params (dict, optional): A dictionary to parameterise the model_fn\n",
    "            (e.g. learning_rate)\n",
    "    Returns:\n",
    "        tf.estimator.EstimatorSpec: A custom EstimatorSpec for this experiment\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. create a model and its outputs\n",
    "    net_output_ops = resnet_3d(\n",
    "        features['x'],\n",
    "        num_res_units=2,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        filters=(16, 32, 64, 128, 256),\n",
    "        strides=((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)),\n",
    "        mode=mode,\n",
    "        kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3))\n",
    "\n",
    "    # 1.1 Generate predictions only (for `ModeKeys.PREDICT`)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=net_output_ops,\n",
    "            export_outputs={'out': tf.estimator.export.PredictOutput(net_output_ops)})\n",
    "\n",
    "    # 2. set up a loss function\n",
    "    one_hot_labels = tf.reshape(tf.one_hot(labels['y'], depth=NUM_CLASSES), [-1, NUM_CLASSES])\n",
    "\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=one_hot_labels,\n",
    "        logits=net_output_ops['logits'])\n",
    "\n",
    "    # 3. define a training op and ops for updating moving averages (i.e. for\n",
    "    # batch normalisation)\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimiser = tf.train.AdamOptimizer(\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        epsilon=1e-5)\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimiser.minimize(loss, global_step=global_step)\n",
    "\n",
    "    # 4.1 (optional) create custom image summaries for tensorboard\n",
    "    my_image_summaries = {}\n",
    "    my_image_summaries['feat_t1'] = features['x'][0, 32, :, :, 0]\n",
    "\n",
    "    expected_output_size = [1, 96, 96, 1]  # [B, W, H, C]\n",
    "    [tf.summary.image(name, tf.reshape(image, expected_output_size))\n",
    "     for name, image in my_image_summaries.items()]\n",
    "\n",
    "    # 4.2 (optional) track the rmse (scaled back by 100, see reader.py)\n",
    "    acc = tf.metrics.accuracy\n",
    "    prec = tf.metrics.precision\n",
    "    eval_metric_ops = {\"accuracy\": acc(labels['y'], net_output_ops['y_']),\n",
    "                       \"precision\": prec(labels['y'], net_output_ops['y_'])}\n",
    "\n",
    "    # 5. Return EstimatorSpec object\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                      predictions=net_output_ops,\n",
    "                                      loss=loss,\n",
    "                                      train_op=train_op,\n",
    "                                      eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    np.random.seed(42)\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    print('Setting up...')\n",
    "\n",
    "    # Parse csv files for file names\n",
    "    all_filenames = pd.read_csv(\n",
    "        args.data_csv,\n",
    "        dtype=object,\n",
    "        keep_default_na=False,\n",
    "        na_values=[]).as_matrix()\n",
    "\n",
    "    train_filenames = all_filenames[:150]\n",
    "    val_filenames = all_filenames[150:]\n",
    "\n",
    "    # Set up a data reader to handle the file i/o.\n",
    "    reader_params = {'n_examples': 2,\n",
    "                     'example_size': [64, 96, 96],\n",
    "                     'extract_examples': True}\n",
    "\n",
    "    reader_example_shapes = {'features': {'x': reader_params['example_size'] + [NUM_CHANNELS]},\n",
    "                             'labels': {'y': [1]}}\n",
    "    reader = Reader(read_fn,\n",
    "                    {'features': {'x': tf.float32},\n",
    "                     'labels': {'y': tf.int32}})\n",
    "\n",
    "    # Get input functions and queue initialisation hooks for training and\n",
    "    # validation data\n",
    "    train_input_fn, train_qinit_hook = reader.get_inputs(\n",
    "        file_references=train_filenames,\n",
    "        mode=tf.estimator.ModeKeys.TRAIN,\n",
    "        example_shapes=reader_example_shapes,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_cache_size=SHUFFLE_CACHE_SIZE,\n",
    "        params=reader_params)\n",
    "\n",
    "    val_input_fn, val_qinit_hook = reader.get_inputs(\n",
    "        file_references=val_filenames,\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        example_shapes=reader_example_shapes,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_cache_size=SHUFFLE_CACHE_SIZE,\n",
    "        params=reader_params)\n",
    "\n",
    "    # Instantiate the neural network estimator\n",
    "    nn = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        model_dir=args.model_path,\n",
    "        params={\"learning_rate\": 0.001},\n",
    "        config=tf.estimator.RunConfig())\n",
    "\n",
    "    # Hooks for validation summaries\n",
    "    val_summary_hook = tf.contrib.training.SummaryAtEndHook(\n",
    "        os.path.join(args.model_path, 'eval'))\n",
    "    step_cnt_hook = tf.train.StepCounterHook(every_n_steps=EVAL_EVERY_N_STEPS,\n",
    "                                             output_dir=args.model_path)\n",
    "\n",
    "    print('Starting training...')\n",
    "    try:\n",
    "        for _ in range(MAX_STEPS // EVAL_EVERY_N_STEPS):\n",
    "            nn.train(\n",
    "                input_fn=train_input_fn,\n",
    "                hooks=[train_qinit_hook, step_cnt_hook],\n",
    "                steps=EVAL_EVERY_N_STEPS)\n",
    "\n",
    "            if args.run_validation:\n",
    "                results_val = nn.evaluate(\n",
    "                    input_fn=val_input_fn,\n",
    "                    hooks=[val_qinit_hook, val_summary_hook],\n",
    "                    steps=EVAL_STEPS)\n",
    "                print('Step = {}; val loss = {:.5f};'.format(\n",
    "                    results_val['global_step'],\n",
    "                    results_val['loss']))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    # When exporting we set the expected input shape to be arbitrary.\n",
    "    export_dir = nn.export_savedmodel(\n",
    "        export_dir_base=args.model_path,\n",
    "        serving_input_receiver_fn=reader.serving_input_receiver_fn(\n",
    "            {'features': {'x': [None, None, None, NUM_CHANNELS]},\n",
    "             'labels': {'y': [1]}}))\n",
    "    print('Model saved to {}.'.format(export_dir))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set up argument parser\n",
    "    parser = argparse.ArgumentParser(description='Example: IXI HH resnet sex classification training')\n",
    "    parser.add_argument('--run_validation', default=True)\n",
    "    parser.add_argument('--restart', default=False, action='store_true')\n",
    "    parser.add_argument('--verbose', default=False, action='store_true')\n",
    "    parser.add_argument('--cuda_devices', '-c', default='0')\n",
    "\n",
    "    parser.add_argument('--model_path', '-p', default='/tmp/IXI_sex_classification/')\n",
    "    parser.add_argument('--data_csv', default='../../../data/IXI_HH/demographic_HH.csv')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Set verbosity\n",
    "    if args.verbose:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "        tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    else:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "        tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "    # GPU allocation options\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda_devices\n",
    "\n",
    "    # Handle restarting and resuming training\n",
    "    if args.restart:\n",
    "        print('Restarting training from scratch.')\n",
    "        os.system('rm -rf {}'.format(args.model_path))\n",
    "\n",
    "    if not os.path.isdir(args.model_path):\n",
    "        os.system('mkdir -p {}'.format(args.model_path))\n",
    "    else:\n",
    "        print('Resuming training on model_path {}'.format(args.model_path))\n",
    "\n",
    "    # Call training\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dltk\n",
    "# !pip install reader\n",
    "# import tensorflow as tf\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (http.py, line 156)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python3.5/site-packages/feedparser/http.py\"\u001b[0;36m, line \u001b[0;32m156\u001b[0m\n\u001b[0;31m    new_pieces[1] = f'{url_pieces.hostname}:{url_pieces.port}'\u001b[0m\n\u001b[0m                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib import predictor\n",
    "\n",
    "from dltk.io.augmentation import extract_random_example_array\n",
    "\n",
    "from reader import read_fn\n",
    "\n",
    "READER_PARAMS = {'extract_examples': False}\n",
    "N_VALIDATION_SUBJECTS = 28\n",
    "\n",
    "\n",
    "def predict(args):\n",
    "    # Read in the csv with the file names you would want to predict on\n",
    "    file_names = pd.read_csv(\n",
    "        args.csv,\n",
    "        dtype=object,\n",
    "        keep_default_na=False,\n",
    "        na_values=[]).as_matrix()\n",
    "\n",
    "    # We trained on the first 4 subjects, so we predict on the rest\n",
    "    file_names = file_names[-N_VALIDATION_SUBJECTS:]\n",
    "\n",
    "    # From the model_path, parse the latest saved model and restore a\n",
    "    # predictor from it\n",
    "    export_dir = \\\n",
    "        [os.path.join(args.model_path, o) for o in sorted(os.listdir(args.model_path))\n",
    "         if os.path.isdir(os.path.join(args.model_path, o)) and o.isdigit()][-1]\n",
    "    print('Loading from {}'.format(export_dir))\n",
    "    my_predictor = predictor.from_saved_model(export_dir)\n",
    "\n",
    "    # Iterate through the files, predict on the full volumes and compute a Dice\n",
    "    # coefficient\n",
    "    accuracy = []\n",
    "    for output in read_fn(file_references=file_names,\n",
    "                          mode=tf.estimator.ModeKeys.EVAL,\n",
    "                          params=READER_PARAMS):\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Parse the read function output and add a dummy batch dimension as\n",
    "        # required\n",
    "        img = output['features']['x']\n",
    "        lbl = output['labels']['y']\n",
    "        test_id = output['img_id']\n",
    "\n",
    "        # We know, that the training input shape of [64, 96, 96] will work with\n",
    "        # our model strides, so we collect several crops of the test image and\n",
    "        # average the predictions. Alternatively, we could pad or crop the input\n",
    "        # to any shape that is compatible with the resolution scales of the\n",
    "        # model:\n",
    "\n",
    "        num_crop_predictions = 4\n",
    "        crop_batch = extract_random_example_array(\n",
    "            image_list=img,\n",
    "            example_size=[64, 96, 96],\n",
    "            n_examples=num_crop_predictions)\n",
    "\n",
    "        y_ = my_predictor.session.run(\n",
    "            fetches=my_predictor._fetch_tensors['y_prob'],\n",
    "            feed_dict={my_predictor._feed_tensors['x']: crop_batch})\n",
    "\n",
    "        # Average the predictions on the cropped test inputs:\n",
    "        y_ = np.mean(y_, axis=0)\n",
    "        predicted_class = np.argmax(y_)\n",
    "\n",
    "        # Calculate the accuracy for this subject\n",
    "        accuracy.append(predicted_class == lbl)\n",
    "\n",
    "        # Print outputs\n",
    "        print('id={}; pred={}; true={}; run time={:0.2f} s; '\n",
    "              ''.format(test_id, predicted_class, lbl[0], time.time() - t0))\n",
    "    print('accuracy={}'.format(np.mean(accuracy)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set up argument parser\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='IXI HH example sex classification deploy script')\n",
    "    parser.add_argument('--verbose', default=False, action='store_true')\n",
    "    parser.add_argument('--cuda_devices', '-c', default='0')\n",
    "\n",
    "    parser.add_argument('--model_path', '-p',\n",
    "                        default='/tmp/IXI_sex_classification/')\n",
    "    parser.add_argument('--csv', default='../../../data/IXI_HH/demographic_HH.csv')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Set verbosity\n",
    "    if args.verbose:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "        tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    else:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "        tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "    # GPU allocation options\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda_devices\n",
    "\n",
    "    # Call training\n",
    "    predict(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only for practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from dltk.io.augmentation import flip, extract_random_example_array\n",
    "from dltk.io.preprocessing import whitening\n",
    "\n",
    "\n",
    "def read_fn(file_references, mode, params=None):\n",
    "    \"\"\"A custom python read function for interfacing with nii image files.\n",
    "    Args:\n",
    "        file_references (list): A list of lists containing file references, such\n",
    "            as [['id_0', 'image_filename_0', target_value_0], ...,\n",
    "            ['id_N', 'image_filename_N', target_value_N]].\n",
    "        mode (str): One of the tf.estimator.ModeKeys strings: TRAIN, EVAL or\n",
    "            PREDICT.\n",
    "        params (dict, optional): A dictionary to parametrise read_fn ouputs\n",
    "            (e.g. reader_params = {'n_examples': 10, 'example_size':\n",
    "            [64, 64, 64], 'extract_examples': True}, etc.).\n",
    "    Yields:\n",
    "        dict: A dictionary of reader outputs for dltk.io.abstract_reader.\n",
    "    \"\"\"\n",
    "\n",
    "    def _augment(img):\n",
    "        \"\"\"An image augmentation function\"\"\"\n",
    "        return flip(img, axis=2)\n",
    "\n",
    "    for f in file_references:\n",
    "        subject_id = f[0]\n",
    "\n",
    "        data_path = '../../../data/IXI_HH/2mm'\n",
    "\n",
    "        # Read the image nii with sitk\n",
    "        t1_fn = os.path.join(data_path, '{}/T1_2mm.nii.gz'.format(subject_id))\n",
    "        t1 = sitk.GetArrayFromImage(sitk.ReadImage(str(t1_fn)))\n",
    "\n",
    "        # Normalise volume image\n",
    "        t1 = whitening(t1)\n",
    "\n",
    "        # Create a 4D image (i.e. [x, y, z, channels])\n",
    "        images = np.expand_dims(t1, axis=-1).astype(np.float32)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            yield {'features': {'x': images}, 'img_id': subject_id}\n",
    "\n",
    "        # Parse the regression targets from the file_references\n",
    "        age = np.float(f[11])\n",
    "        y = np.expand_dims(age, axis=-1).astype(np.float32)\n",
    "\n",
    "        # Augment if used in training mode\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            images = _augment(images)\n",
    "\n",
    "        # Check if the reader is supposed to return training examples or full\n",
    "        #  images\n",
    "        if params['extract_examples']:\n",
    "            images = extract_random_example_array(\n",
    "                image_list=images,\n",
    "                example_size=params['example_size'],\n",
    "                n_examples=params['n_examples'])\n",
    "\n",
    "            for e in range(params['n_examples']):\n",
    "                yield {'features': {'x': images[e].astype(np.float32)},\n",
    "                       'labels': {'y': y.astype(np.float32)},\n",
    "                       'img_id': subject_id}\n",
    "\n",
    "        else:\n",
    "            yield {'features': {'x': images},\n",
    "                   'labels': {'y': y.astype(np.float32)},\n",
    "                   'img_id': subject_id}\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from dltk.networks.regression_classification.resnet import resnet_3d\n",
    "from dltk.io.abstract_reader import Reader\n",
    "\n",
    "from reader import read_fn\n",
    "\n",
    "EVAL_EVERY_N_STEPS = 100\n",
    "EVAL_STEPS = 5\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "SHUFFLE_CACHE_SIZE = 32\n",
    "\n",
    "MAX_STEPS = 50000\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    \"\"\"Model function to construct a tf.estimator.EstimatorSpec. It creates a\n",
    "        network given input features (e.g. from a dltk.io.abstract_reader) and\n",
    "        training targets (labels). Further, loss, optimiser, evaluation ops and\n",
    "        custom tensorboard summary ops can be added. For additional information,\n",
    "        please refer to\n",
    "        https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#model_fn.\n",
    "    Args:\n",
    "        features (tf.Tensor): Tensor of input features to train from. Required\n",
    "            rank and dimensions are determined by the subsequent ops (i.e.\n",
    "            the network).\n",
    "        labels (tf.Tensor): Tensor of training targets or labels. Required rank\n",
    "            and dimensions are determined by the network output.\n",
    "        mode (str): One of the tf.estimator.ModeKeys: TRAIN, EVAL or PREDICT\n",
    "        params (dict, optional): A dictionary to parameterise the model_fn\n",
    "            (e.g. learning_rate)\n",
    "    Returns:\n",
    "        tf.estimator.EstimatorSpec: A custom EstimatorSpec for this experiment\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. create a model and its outputs\n",
    "    net_output_ops = resnet_3d(\n",
    "        inputs=features['x'],\n",
    "        num_res_units=2,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        filters=(16, 32, 64, 128, 256),\n",
    "        strides=((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)),\n",
    "        mode=mode,\n",
    "        kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-4))\n",
    "\n",
    "    # 1.1 Generate predictions only (for `ModeKeys.PREDICT`)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=net_output_ops,\n",
    "            export_outputs={'out': tf.estimator.export.PredictOutput(net_output_ops)})\n",
    "\n",
    "    # 2. set up a loss function\n",
    "    loss = tf.losses.mean_squared_error(\n",
    "        labels=labels['y'],\n",
    "        predictions=net_output_ops['logits'])\n",
    "\n",
    "    # 3. define a training op and ops for updating moving averages (i.e.\n",
    "    # for batch normalisation)\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimiser = tf.train.AdamOptimizer(\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        epsilon=1e-5)\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimiser.minimize(loss, global_step=global_step)\n",
    "\n",
    "    # 4.1 (optional) create custom image summaries for tensorboard\n",
    "    my_image_summaries = {}\n",
    "    my_image_summaries['feat_t1'] = features['x'][0, 32, :, :, 0]\n",
    "\n",
    "    expected_output_size = [1, 96, 96, 1]  # [B, W, H, C]\n",
    "    [tf.summary.image(name, tf.reshape(image, expected_output_size))\n",
    "     for name, image in my_image_summaries.items()]\n",
    "\n",
    "    # 4.2 (optional) track the rmse (scaled back by 100, see reader.py)\n",
    "    rmse = tf.metrics.root_mean_squared_error\n",
    "    mae = tf.metrics.mean_absolute_error\n",
    "    eval_metric_ops = {\"rmse\": rmse(labels['y'], net_output_ops['logits']),\n",
    "                       \"mae\": mae(labels['y'], net_output_ops['logits'])}\n",
    "\n",
    "    # 5. Return EstimatorSpec object\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                      predictions=net_output_ops,\n",
    "                                      loss=loss,\n",
    "                                      train_op=train_op,\n",
    "                                      eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    np.random.seed(42)\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    print('Setting up...')\n",
    "\n",
    "    # Parse csv files for file names\n",
    "    all_filenames = pd.read_csv(\n",
    "        args.data_csv,\n",
    "        dtype=object,\n",
    "        keep_default_na=False,\n",
    "        na_values=[]).as_matrix()\n",
    "\n",
    "    train_filenames = all_filenames[:150]\n",
    "    val_filenames = all_filenames[150:]\n",
    "\n",
    "    # Set up a data reader to handle the file i/o.\n",
    "    reader_params = {'n_examples': 2,\n",
    "                     'example_size': [64, 96, 96],\n",
    "                     'extract_examples': True}\n",
    "\n",
    "    reader_example_shapes = {'features': {'x': reader_params['example_size'] + [NUM_CHANNELS, ]},\n",
    "                             'labels': {'y': [1]}}\n",
    "\n",
    "    reader = Reader(read_fn, {'features': {'x': tf.float32},\n",
    "                              'labels': {'y': tf.float32}})\n",
    "\n",
    "    # Get input functions and queue initialisation hooks for training and\n",
    "    # validation data\n",
    "    train_input_fn, train_qinit_hook = reader.get_inputs(\n",
    "        file_references=train_filenames,\n",
    "        mode=tf.estimator.ModeKeys.TRAIN,\n",
    "        example_shapes=reader_example_shapes,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_cache_size=SHUFFLE_CACHE_SIZE,\n",
    "        params=reader_params)\n",
    "\n",
    "    val_input_fn, val_qinit_hook = reader.get_inputs(\n",
    "        file_references=val_filenames,\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        example_shapes=reader_example_shapes,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle_cache_size=SHUFFLE_CACHE_SIZE,\n",
    "        params=reader_params)\n",
    "\n",
    "    # Instantiate the neural network estimator\n",
    "    nn = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        model_dir=args.model_path,\n",
    "        params={\"learning_rate\": 0.001},\n",
    "        config=tf.estimator.RunConfig())\n",
    "\n",
    "    # Hooks for validation summaries\n",
    "    val_summary_hook = tf.contrib.training.SummaryAtEndHook(\n",
    "        os.path.join(args.model_path, 'eval'))\n",
    "    step_cnt_hook = tf.train.StepCounterHook(\n",
    "        every_n_steps=EVAL_EVERY_N_STEPS, output_dir=args.model_path)\n",
    "\n",
    "    print('Starting training...')\n",
    "    try:\n",
    "        for _ in range(MAX_STEPS // EVAL_EVERY_N_STEPS):\n",
    "            nn.train(input_fn=train_input_fn,\n",
    "                     hooks=[train_qinit_hook, step_cnt_hook],\n",
    "                     steps=EVAL_EVERY_N_STEPS)\n",
    "\n",
    "            if args.run_validation:\n",
    "                results_val = nn.evaluate(input_fn=val_input_fn,\n",
    "                                          hooks=[val_qinit_hook, val_summary_hook],\n",
    "                                          steps=EVAL_STEPS)\n",
    "                print('Step = {}; val loss = {:.5f};'.format(\n",
    "                    results_val['global_step'],\n",
    "                    results_val['loss']))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    print('Stopping now.')\n",
    "\n",
    "    # When exporting we set the expected input shape to be arbitrary.\n",
    "    export_dir = nn.export_savedmodel(\n",
    "        export_dir_base=args.model_path,\n",
    "        serving_input_receiver_fn=reader.serving_input_receiver_fn(\n",
    "            {'features': {'x': [None, None, None, NUM_CHANNELS]},\n",
    "             'labels': {'y': [1]}}))\n",
    "    print('Model saved to {}.'.format(export_dir))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set up argument parser\n",
    "    parser = argparse.ArgumentParser(description='Example: IXI HH resnet age regression training script')\n",
    "    parser.add_argument('--run_validation', default=True)\n",
    "    parser.add_argument('--restart', default=False, action='store_true')\n",
    "    parser.add_argument('--verbose', default=False, action='store_true')\n",
    "    parser.add_argument('--cuda_devices', '-c', default='0')\n",
    "\n",
    "    parser.add_argument('--model_path', '-p', default='/tmp/IXI_age_regression/')\n",
    "    parser.add_argument('--data_csv', default='../../../data/IXI_HH/demographic_HH.csv')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Set verbosity\n",
    "    if args.verbose:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "        tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    else:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "        tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "    # GPU allocation options\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda_devices\n",
    "\n",
    "    # Handle restarting and resuming training\n",
    "    if args.restart:\n",
    "        print('Restarting training from scratch.')\n",
    "        os.system('rm -rf {}'.format(args.model_path))\n",
    "\n",
    "    if not os.path.isdir(args.model_path):\n",
    "        os.system('mkdir -p {}'.format(args.model_path))\n",
    "    else:\n",
    "        print('Resuming training on model_path {}'.format(args.model_path))\n",
    "\n",
    "    # Call training\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import predictor\n",
    "\n",
    "from dltk.io.augmentation import extract_random_example_array\n",
    "\n",
    "from reader import read_fn\n",
    "\n",
    "READER_PARAMS = {'extract_examples': False}\n",
    "N_VALIDATION_SUBJECTS = 28\n",
    "\n",
    "\n",
    "def predict(args):\n",
    "    # Read in the csv with the file names you would want to predict on\n",
    "    file_names = pd.read_csv(\n",
    "        args.csv,\n",
    "        dtype=object,\n",
    "        keep_default_na=False,\n",
    "        na_values=[]).as_matrix()\n",
    "\n",
    "    # We trained on the first 4 subjects, so we predict on the rest\n",
    "    file_names = file_names[-N_VALIDATION_SUBJECTS:]\n",
    "\n",
    "    # From the model_path, parse the latest saved model and restore a\n",
    "    # predictor from it\n",
    "    export_dir = [os.path.join(args.model_path, o) for o in sorted(\n",
    "        os.listdir(args.model_path)) if os.path.isdir(\n",
    "        os.path.join(args.model_path, o)) and o.isdigit()][-1]\n",
    "\n",
    "    print('Loading from {}'.format(export_dir))\n",
    "    my_predictor = predictor.from_saved_model(export_dir)\n",
    "\n",
    "    # Iterate through the files, predict on the full volumes and compute a Dice\n",
    "    # coefficient\n",
    "    mae = []\n",
    "    for output in read_fn(file_references=file_names,\n",
    "                          mode=tf.estimator.ModeKeys.EVAL,\n",
    "                          params=READER_PARAMS):\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Parse the read function output and add a dummy batch dimension as\n",
    "        # required\n",
    "        img = output['features']['x']\n",
    "        lbl = output['labels']['y']\n",
    "        test_id = output['img_id']\n",
    "\n",
    "        # We know, that the training input shape of [64, 96, 96] will work with\n",
    "        # our model strides, so we collect several crops of the test image and\n",
    "        # average the predictions. Alternatively, we could pad or crop the input\n",
    "        # to any shape that is compatible with the resolution scales of the\n",
    "        # model:\n",
    "\n",
    "        num_crop_predictions = 4\n",
    "        crop_batch = extract_random_example_array(\n",
    "            image_list=img,\n",
    "            example_size=[64, 96, 96],\n",
    "            n_examples=num_crop_predictions)\n",
    "\n",
    "        y_ = my_predictor.session.run(\n",
    "            fetches=my_predictor._fetch_tensors['logits'],\n",
    "            feed_dict={my_predictor._feed_tensors['x']: crop_batch})\n",
    "\n",
    "        # Average the predictions on the cropped test inputs:\n",
    "        y_ = np.mean(y_)\n",
    "\n",
    "        # Calculate the absolute error for this subject\n",
    "        mae.append(np.abs(y_ - lbl))\n",
    "\n",
    "        # Print outputs\n",
    "        print('id={}; pred={:0.2f} yrs; true={:0.2f} yrs; run time={:0.2f} s; '\n",
    "              ''.format(test_id, y_, lbl[0], time.time() - t0))\n",
    "    print('mean absolute err={:0.3f} yrs'.format(np.mean(mae)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set up argument parser\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='IXI HH example age regression deploy script')\n",
    "    parser.add_argument('--verbose', default=False, action='store_true')\n",
    "    parser.add_argument('--cuda_devices', '-c', default='0')\n",
    "\n",
    "    parser.add_argument('--model_path', '-p',\n",
    "                        default='/tmp/IXI_age_regression/')\n",
    "    parser.add_argument('--csv', default='../../../data/IXI_HH/demographic_HH.csv')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Set verbosity\n",
    "    if args.verbose:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "        tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    else:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "        tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "    # GPU allocation options\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda_devices\n",
    "\n",
    "    # Call training\n",
    "    predict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
